{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7aa64a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Odisha districts loaded: (58, 17)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# 📍 Path to input district boundary GeoJSON\n",
    "districts_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Datasets\\shapefile\\odisha_districts.geojson\"\n",
    "\n",
    "# 📂 Final output folder (create if doesn't exist)\n",
    "final_folder = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\"\n",
    "os.makedirs(final_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Load district boundaries\n",
    "districts_gdf = gpd.read_file(districts_path)\n",
    "print(\"✅ Odisha districts loaded:\", districts_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee61cada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Odisha districts loaded: (58, 17)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "\n",
    "# 📍 Path to input district boundary GeoJSON\n",
    "districts_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Datasets\\shapefile\\odisha_districts.geojson\"\n",
    "\n",
    "# 📂 Final output folder (create if doesn't exist)\n",
    "final_folder = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\"\n",
    "os.makedirs(final_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Load district boundaries\n",
    "districts_gdf = gpd.read_file(districts_path)\n",
    "print(\"✅ Odisha districts loaded:\", districts_gdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cc56930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Empty master village template saved at:\n",
      "C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_template.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 🧾 Define schema for cleaned master villages file\n",
    "village_master_columns = [\n",
    "    \"village_id\", \"village_name\", \"district\", \"subdistrict\",\n",
    "    \"lgd_villagecode\", \"lgd_subdistrictcode\", \"lgd_districtcode\",\n",
    "    \"population_2024\", \"geometry\"  # geometry to be centroid Point\n",
    "]\n",
    "\n",
    "# Create empty dataframe\n",
    "master_village_df = pd.DataFrame(columns=village_master_columns)\n",
    "\n",
    "# 📁 Save template CSV\n",
    "master_csv_path = os.path.join(final_folder, \"master_villages_template.csv\")\n",
    "master_village_df.to_csv(master_csv_path, index=False)\n",
    "print(f\"✅ Empty master village template saved at:\\n{master_csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "062caee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned master village template saved with final columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "final_folder = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\"\n",
    "\n",
    "final_columns = [\n",
    "    \"village_id\",\n",
    "    \"village_name\",\n",
    "    \"district\",\n",
    "    \"subdistrict\",\n",
    "    \"lgd_villagecode\",\n",
    "    \"lgd_subdistrictcode\",\n",
    "    \"lgd_districtcode\",\n",
    "    \"population_2024\",\n",
    "    \"geometry\"\n",
    "]\n",
    "\n",
    "# Create empty DataFrame\n",
    "clean_village_df = pd.DataFrame(columns=final_columns)\n",
    "\n",
    "# Save final version\n",
    "final_csv_path = os.path.join(final_folder, \"master_villages_template.csv\")\n",
    "clean_village_df.to_csv(final_csv_path, index=False)\n",
    "\n",
    "print(\"✅ Cleaned master village template saved with final columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bb54ec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\AppData\\Local\\Temp\\ipykernel_6036\\726780118.py:16: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  villages_gdf[\"geometry\"] = villages_gdf.geometry.centroid\n",
      "C:\\Users\\utkar\\AppData\\Local\\Temp\\ipykernel_6036\\726780118.py:55: UserWarning: Geometry column does not contain geometry.\n",
      "  villages_csv[\"geometry\"] = villages_csv[\"geometry\"].apply(lambda geom: geom.wkt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎉 Saved: master_villages_final.geojson and .csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 📍 Input village GeoJSON path\n",
    "input_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\GIS Data\\Village Boundaries\\Odisha_Villages.geojson\"\n",
    "\n",
    "# 📁 Output folder\n",
    "output_folder = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# ✅ Step 1: Load village polygons\n",
    "villages_gdf = gpd.read_file(input_path)\n",
    "\n",
    "# ✅ Step 2: Convert polygons to centroids (if needed)\n",
    "villages_gdf[\"geometry\"] = villages_gdf.geometry.centroid\n",
    "\n",
    "# ✅ Step 3: Rename and select relevant columns\n",
    "villages_gdf = villages_gdf.rename(columns={\n",
    "    \"village_name\": \"village_name\",  # Update if different\n",
    "    \"district\": \"district\",\n",
    "    \"subdistrict\": \"subdistrict\",\n",
    "    \"lgd_villagecode\": \"lgd_villagecode\",\n",
    "    \"lgd_subdistrictcode\": \"lgd_subdistrictcode\",\n",
    "    \"lgd_districtcode\": \"lgd_districtcode\",\n",
    "    \"population_2024\": \"population_2024\"  # Optional, only if available\n",
    "})\n",
    "\n",
    "# ✅ Step 4: Generate unique village ID\n",
    "villages_gdf[\"village_id\"] = (\n",
    "    villages_gdf[\"lgd_districtcode\"].astype(str) + \"_\" +\n",
    "    villages_gdf[\"lgd_villagecode\"].astype(str)\n",
    ")\n",
    "\n",
    "# ✅ Step 5: Final column order\n",
    "final_columns = [\n",
    "    \"village_id\",\n",
    "    \"village_name\",\n",
    "    \"district\",\n",
    "    \"subdistrict\",\n",
    "    \"lgd_villagecode\",\n",
    "    \"lgd_subdistrictcode\",\n",
    "    \"lgd_districtcode\",\n",
    "    \"population_2024\",  # Only if available\n",
    "    \"geometry\"\n",
    "]\n",
    "\n",
    "villages_cleaned = villages_gdf[[col for col in final_columns if col in villages_gdf.columns]]\n",
    "\n",
    "# ✅ Step 6: Save GeoJSON\n",
    "villages_cleaned.to_file(os.path.join(output_folder, \"master_villages_final.geojson\"), driver=\"GeoJSON\")\n",
    "\n",
    "# ✅ Step 7: Save CSV (with geometry as WKT)\n",
    "villages_csv = villages_cleaned.copy()\n",
    "villages_csv[\"geometry\"] = villages_csv[\"geometry\"].apply(lambda geom: geom.wkt)\n",
    "villages_csv.to_csv(os.path.join(output_folder, \"master_villages_final.csv\"), index=False)\n",
    "\n",
    "print(\"🎉 Saved: master_villages_final.geojson and .csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16941230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 💡 Reproject to UTM Zone 45N (India East) for accurate centroid computation\n",
    "villages_gdf = villages_gdf.to_crs(epsg=32645)\n",
    "\n",
    "# ✅ Now compute centroid\n",
    "villages_gdf[\"geometry\"] = villages_gdf.geometry.centroid\n",
    "\n",
    "# 🔁 Reproject back to EPSG:4326 (WGS 84) for saving and snapping\n",
    "villages_gdf = villages_gdf.to_crs(epsg=4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2d5fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Duplicate village_id entries: 1861\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['village_name'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m🔍 Duplicate village_id entries: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_duplicates\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_duplicates > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mduplicate_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvillage_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdistrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvillage_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# ✅ 2. Count number of villages per district\u001b[39;00m\n\u001b[32m     16\u001b[39m district_counts = villages.groupby(\u001b[33m\"\u001b[39m\u001b[33mdistrict\u001b[39m\u001b[33m\"\u001b[39m).size().reset_index(name=\u001b[33m\"\u001b[39m\u001b[33mvillage_count\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Lib\\site-packages\\geopandas\\geodataframe.py:1750\u001b[39m, in \u001b[36mGeoDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m   1745\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[33;03m    If the result is a column containing only 'geometry', return a\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[33;03m    GeoSeries. If it's a DataFrame with any columns of GeometryDtype,\u001b[39;00m\n\u001b[32m   1748\u001b[39m \u001b[33;03m    return a GeoDataFrame.\u001b[39;00m\n\u001b[32m   1749\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     result = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1751\u001b[39m     \u001b[38;5;66;03m# Custom logic to avoid waiting for pandas GH51895\u001b[39;00m\n\u001b[32m   1752\u001b[39m     \u001b[38;5;66;03m# result is not geometry dtype for multi-indexes\u001b[39;00m\n\u001b[32m   1753\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1754\u001b[39m         pd.api.types.is_scalar(key)\n\u001b[32m   1755\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m key == \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1758\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_geometry_type(result)\n\u001b[32m   1759\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['village_name'] not in index\""
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# 📍 Load final master village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# ✅ 1. Check for duplicate village IDs\n",
    "duplicate_ids = villages[villages.duplicated(subset=\"village_id\", keep=False)]\n",
    "num_duplicates = duplicate_ids.shape[0]\n",
    "print(f\"🔍 Duplicate village_id entries: {num_duplicates}\")\n",
    "if num_duplicates > 0:\n",
    "    print(duplicate_ids[[\"village_id\", \"district\", \"village_name\"]])\n",
    "\n",
    "# ✅ 2. Count number of villages per district\n",
    "district_counts = villages.groupby(\"district\").size().reset_index(name=\"village_count\")\n",
    "print(\"\\n📊 Village count per district:\")\n",
    "print(district_counts)\n",
    "\n",
    "# ✅ 3. Check for missing values in key columns\n",
    "missing_summary = villages[[\n",
    "    \"village_id\", \"village_name\", \"district\", \"lgd_villagecode\", \"geometry\"\n",
    "]].isnull().sum()\n",
    "print(\"\\n🚨 Missing value check:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49193738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['village_id', 'district', 'subdistrict', 'lgd_villagecode', 'lgd_subdistrictcode', 'lgd_districtcode', 'geometry']\n"
     ]
    }
   ],
   "source": [
    "print(villages.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b82b1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Duplicate village_id entries: 1861\n",
      "\n",
      "🛠️ Sample duplicate entries:\n",
      "   village_id    district  lgd_villagecode  lgd_districtcode\n",
      "5     364_nan  Malkangiri              NaN               364\n",
      "6     364_nan  Malkangiri              NaN               364\n",
      "7     364_nan  Malkangiri              NaN               364\n",
      "13    364_nan  Malkangiri              NaN               364\n",
      "25    364_nan  Malkangiri              NaN               364\n",
      "28    364_nan  Malkangiri              NaN               364\n",
      "30    364_nan  Malkangiri              NaN               364\n",
      "31    364_nan  Malkangiri              NaN               364\n",
      "32    364_nan  Malkangiri              NaN               364\n",
      "33    364_nan  Malkangiri              NaN               364\n",
      "\n",
      "📊 Village count per district:\n",
      "          district  village_count\n",
      "0           Anugul           1993\n",
      "1         Balangir           1875\n",
      "2        Baleshwar           2946\n",
      "3          Bargarh           1280\n",
      "4          Bhadrak           1322\n",
      "5            Boudh           1233\n",
      "6          Cuttack           1992\n",
      "7          Deogarh            906\n",
      "8        Dhenkanal           1248\n",
      "9         Gajapati           1647\n",
      "10          Ganjam           3328\n",
      "11  Jagatsinghapur           1300\n",
      "12         Jajapur           1799\n",
      "13      Jharsuguda            382\n",
      "14       Kalahandi           2360\n",
      "15       Kandhamal           2737\n",
      "16      Kendrapara           1560\n",
      "17       Kendujhar           2183\n",
      "18         Khordha           1562\n",
      "19         Koraput           2227\n",
      "20      Malkangiri           1143\n",
      "21      Mayurbhanj           3991\n",
      "22     Nabarangpur            943\n",
      "23        Nayagarh           1755\n",
      "24         Nuapada            719\n",
      "25            Puri           1716\n",
      "26        Rayagada           2825\n",
      "27       Sambalpur           1415\n",
      "28         Sonepur           1001\n",
      "29      Sundargarh           1933\n",
      "\n",
      "🚨 Missing value check:\n",
      "village_id            0\n",
      "district              0\n",
      "lgd_villagecode    1852\n",
      "geometry              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# 📍 Load final master village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# ✅ 1. Check for duplicate village IDs\n",
    "duplicate_ids = villages[villages.duplicated(subset=\"village_id\", keep=False)]\n",
    "num_duplicates = duplicate_ids.shape[0]\n",
    "print(f\"🔍 Duplicate village_id entries: {num_duplicates}\")\n",
    "\n",
    "# Show first 10 duplicates with district and codes\n",
    "if num_duplicates > 0:\n",
    "    print(\"\\n🛠️ Sample duplicate entries:\")\n",
    "    print(duplicate_ids[[\"village_id\", \"district\", \"lgd_villagecode\", \"lgd_districtcode\"]].head(10))\n",
    "\n",
    "# ✅ 2. Count number of villages per district\n",
    "district_counts = villages.groupby(\"district\").size().reset_index(name=\"village_count\")\n",
    "print(\"\\n📊 Village count per district:\")\n",
    "print(district_counts)\n",
    "\n",
    "# ✅ 3. Check for missing values in key columns\n",
    "missing_summary = villages[[\n",
    "    \"village_id\", \"district\", \"lgd_villagecode\", \"geometry\"\n",
    "]].isnull().sum()\n",
    "print(\"\\n🚨 Missing value check:\")\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d323f477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Column: village_id\n",
      "   ➤ Unique values: 51493\n",
      "   ➤ Total rows:    53321\n",
      "   ➤ Is Unique:     ❌ No\n",
      "\n",
      "🔍 Column: lgd_villagecode\n",
      "   ➤ Unique values: 51464\n",
      "   ➤ Total rows:    53321\n",
      "   ➤ Is Unique:     ❌ No\n",
      "\n",
      "🔍 Column: geometry\n",
      "   ➤ Unique values: 53321\n",
      "   ➤ Total rows:    53321\n",
      "   ➤ Is Unique:     ✅ Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# Check uniqueness of key columns\n",
    "columns_to_check = [\"village_id\", \"lgd_villagecode\", \"geometry\"]\n",
    "\n",
    "for col in columns_to_check:\n",
    "    unique_count = villages[col].nunique()\n",
    "    total_count = len(villages)\n",
    "    print(f\"🔍 Column: {col}\")\n",
    "    print(f\"   ➤ Unique values: {unique_count}\")\n",
    "    print(f\"   ➤ Total rows:    {total_count}\")\n",
    "    print(f\"   ➤ Is Unique:     {'✅ Yes' if unique_count == total_count else '❌ No'}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0c80f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total duplicate LGD codes found: 10\n",
      "📏 Duplicate entries within 100 meters: 0\n",
      "Empty DataFrame\n",
      "Columns: [lgd_villagecode, district, distance_m]\n",
      "Index: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Lib\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "\n",
    "# Load master village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# Step 1: Keep only rows with non-null LGD village codes\n",
    "villages_valid = villages.dropna(subset=[\"lgd_villagecode\"])\n",
    "\n",
    "# Step 2: Convert LGD codes to string for safe deduplication\n",
    "villages_valid[\"lgd_villagecode\"] = villages_valid[\"lgd_villagecode\"].astype(str)\n",
    "\n",
    "# Step 3: Identify duplicate LGD codes\n",
    "duplicate_lgd = villages_valid[villages_valid.duplicated(\"lgd_villagecode\", keep=False)]\n",
    "\n",
    "# Step 4: Check spatial proximity of duplicates (within 100 meters)\n",
    "duplicate_lgd = duplicate_lgd.to_crs(epsg=32645)  # Projected CRS for distance check\n",
    "duplicate_lgd[\"group\"] = duplicate_lgd[\"lgd_villagecode\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "# Group by LGD code and compute distances\n",
    "for lgd_code, group in duplicate_lgd.groupby(\"group\"):\n",
    "    if len(group) > 1:\n",
    "        for i in range(len(group)):\n",
    "            for j in range(i + 1, len(group)):\n",
    "                geom1 = group.iloc[i].geometry\n",
    "                geom2 = group.iloc[j].geometry\n",
    "                dist_m = geom1.distance(geom2)\n",
    "                results.append({\n",
    "                    \"lgd_villagecode\": lgd_code,\n",
    "                    \"district\": group.iloc[i][\"district\"],\n",
    "                    \"distance_m\": dist_m\n",
    "                })\n",
    "\n",
    "# Compile results\n",
    "import pandas as pd\n",
    "distance_df = pd.DataFrame(results)\n",
    "\n",
    "# Filter only nearby duplicates (within 100 meters)\n",
    "nearby = distance_df[distance_df[\"distance_m\"] <= 100]\n",
    "\n",
    "print(\"🔍 Total duplicate LGD codes found:\", len(duplicate_lgd))\n",
    "print(\"📏 Duplicate entries within 100 meters:\", len(nearby))\n",
    "print(nearby.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4ec4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total duplicate LGD village codes: 1862\n",
      "      lgd_villagecode    district    subdistrict                   geometry\n",
      "46985        250486.0   Baleshwar        Bampada  POINT (86.86981 21.50248)\n",
      "46958        250486.0   Baleshwar  Baleshwar (M)   POINT (86.92138 21.4962)\n",
      "14610        250531.0      Ganjam       Gopalpur  POINT (84.90294 19.25936)\n",
      "15109        250531.0      Ganjam  Purusottampur   POINT (84.8825 19.52108)\n",
      "33321        400144.0     Cuttack       C.R.R.I.  POINT (85.96163 20.44256)\n",
      "33380        400144.0     Cuttack      Kandarpur  POINT (85.96267 20.43463)\n",
      "34599        400165.0     Cuttack      Kandarpur  POINT (85.97826 20.42153)\n",
      "34640        400165.0     Cuttack       C.R.R.I.  POINT (85.97464 20.43029)\n",
      "1227         429429.0     Koraput    Boipariguda  POINT (82.32086 18.71472)\n",
      "1922         429429.0     Koraput        Kundura   POINT (82.3231 18.98642)\n",
      "26488             nan     Bargarh     Jharbandha  POINT (82.89683 21.10017)\n",
      "26494             nan     Bargarh     Jharbandha  POINT (82.88856 21.12339)\n",
      "26493             nan     Bargarh     Jharbandha  POINT (82.83095 21.12473)\n",
      "26544             nan     Bargarh   Melchhamunda  POINT (83.21895 21.09362)\n",
      "26545             nan     Bargarh   Melchhamunda  POINT (83.22497 21.16715)\n",
      "26546             nan     Bargarh         Sohela  POINT (83.24142 21.24789)\n",
      "26491             nan     Bargarh     Jharbandha  POINT (82.90588 21.10975)\n",
      "26487             nan     Bargarh     Jharbandha  POINT (82.96244 21.14847)\n",
      "5                 nan  Malkangiri           Motu  POINT (81.47699 17.85953)\n",
      "26446             nan   Sambalpur      Rairakhol  POINT (84.40723 21.05369)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# Load the master village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# Clean LGD village codes to string for safety\n",
    "villages[\"lgd_villagecode\"] = villages[\"lgd_villagecode\"].astype(str).str.strip()\n",
    "\n",
    "# Filter only rows with valid LGD codes\n",
    "villages_valid = villages.dropna(subset=[\"lgd_villagecode\"]).copy()\n",
    "\n",
    "# Identify duplicates\n",
    "dupes = villages_valid[villages_valid.duplicated(subset=\"lgd_villagecode\", keep=False)]\n",
    "\n",
    "# Show first 20 duplicates with relevant fields\n",
    "print(f\"🔍 Total duplicate LGD village codes: {dupes.shape[0]}\")\n",
    "dupes_display = dupes[[\"lgd_villagecode\", \"district\", \"subdistrict\", \"geometry\"]].sort_values(\"lgd_villagecode\")\n",
    "print(dupes_display.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43aa4516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Duplicate LGD villages exported:\n",
      "📁 C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\duplicate_lgd_villages.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\AppData\\Local\\Temp\\ipykernel_6036\\3918458135.py:19: UserWarning: Geometry column does not contain geometry.\n",
      "  dupes[\"geometry\"] = dupes[\"geometry\"].apply(lambda g: g.wkt)\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load the master village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# Clean and cast LGD village codes\n",
    "villages[\"lgd_villagecode\"] = villages[\"lgd_villagecode\"].astype(str).str.strip()\n",
    "\n",
    "# Filter only valid LGD codes\n",
    "villages_valid = villages.dropna(subset=[\"lgd_villagecode\"]).copy()\n",
    "\n",
    "# Find duplicates\n",
    "dupes = villages_valid[villages_valid.duplicated(subset=\"lgd_villagecode\", keep=False)].copy()\n",
    "\n",
    "# Reorder columns and convert geometry to WKT\n",
    "dupes[\"geometry\"] = dupes[\"geometry\"].apply(lambda g: g.wkt)\n",
    "\n",
    "# Define output path\n",
    "output_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\duplicate_lgd_villages.csv\"\n",
    "\n",
    "# Save as CSV\n",
    "dupes.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Duplicate LGD villages exported:\\n📁 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6293b17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📏 Pairwise distance analysis complete.\n",
      "🧾 Results saved to:\n",
      "C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\duplicate_lgd_distances.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import nearest_points\n",
    "import pandas as pd\n",
    "\n",
    "# Step 1: Reload duplicates from original GeoJSON to retain geometry\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# Filter valid LGD codes and identify duplicates\n",
    "villages[\"lgd_villagecode\"] = villages[\"lgd_villagecode\"].astype(str).str.strip()\n",
    "villages_valid = villages.dropna(subset=[\"lgd_villagecode\"]).copy()\n",
    "dupes = villages_valid[villages_valid.duplicated(subset=\"lgd_villagecode\", keep=False)].copy()\n",
    "\n",
    "# Step 2: Reproject to UTM Zone 45N for accurate distance computation (EPSG:32645)\n",
    "dupes = dupes.to_crs(epsg=32645)\n",
    "\n",
    "# Step 3: Compute pairwise distances for each duplicate LGD code group\n",
    "results = []\n",
    "for code, group in dupes.groupby(\"lgd_villagecode\"):\n",
    "    if len(group) > 1:\n",
    "        for i in range(len(group)):\n",
    "            for j in range(i + 1, len(group)):\n",
    "                geom1 = group.iloc[i].geometry\n",
    "                geom2 = group.iloc[j].geometry\n",
    "                dist_m = geom1.distance(geom2)\n",
    "                results.append({\n",
    "                    \"lgd_villagecode\": code,\n",
    "                    \"district_1\": group.iloc[i][\"district\"],\n",
    "                    \"subdistrict_1\": group.iloc[i][\"subdistrict\"],\n",
    "                    \"district_2\": group.iloc[j][\"district\"],\n",
    "                    \"subdistrict_2\": group.iloc[j][\"subdistrict\"],\n",
    "                    \"distance_m\": dist_m\n",
    "                })\n",
    "\n",
    "# Step 4: Create result DataFrame and flag nearby/far\n",
    "distance_df = pd.DataFrame(results)\n",
    "distance_df[\"proximity\"] = pd.cut(distance_df[\"distance_m\"], \n",
    "                                   bins=[0, 500, 1000, float(\"inf\")], \n",
    "                                   labels=[\"Very Close (<500m)\", \"Nearby (500m–1km)\", \"Far (>1km)\"])\n",
    "\n",
    "# Step 5: Save for inspection\n",
    "output_dist_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\duplicate_lgd_distances.csv\"\n",
    "distance_df.to_csv(output_dist_path, index=False)\n",
    "\n",
    "print(f\"📏 Pairwise distance analysis complete.\")\n",
    "print(f\"🧾 Results saved to:\\n{output_dist_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "265ca363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Summary of Duplicate LGD Village Proximities:\n",
      "\n",
      "      Proximity Range  Number of Duplicate Pairs\n",
      "0          Far (>1km)                    1713988\n",
      "1   Nearby (500m–1km)                         32\n",
      "2  Very Close (<500m)                         11\n",
      "\n",
      "🔎 Farthest duplicate LGD entries:\n",
      "       lgd_villagecode  district_1 subdistrict_1 district_2 subdistrict_2  \\\n",
      "5412               NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "3563               NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "1713               NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "20168              NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "7260               NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "14642              NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "12798              NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "16485              NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "18327              NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "10953              NaN  Malkangiri          Motu  Baleshwar       Bhograi   \n",
      "\n",
      "          distance_m   proximity  \n",
      "5412   748138.329055  Far (>1km)  \n",
      "3563   747473.793798  Far (>1km)  \n",
      "1713   745278.453426  Far (>1km)  \n",
      "20168  744051.069655  Far (>1km)  \n",
      "7260   743491.520415  Far (>1km)  \n",
      "14642  743336.084940  Far (>1km)  \n",
      "12798  741758.027662  Far (>1km)  \n",
      "16485  741416.285674  Far (>1km)  \n",
      "18327  740849.847509  Far (>1km)  \n",
      "10953  740002.063548  Far (>1km)  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 📍 Path to pairwise distance file\n",
    "distance_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\duplicate_lgd_distances.csv\"\n",
    "\n",
    "# ✅ Load the CSV\n",
    "distances_df = pd.read_csv(distance_path)\n",
    "\n",
    "# 🔍 Summary by proximity category\n",
    "summary = distances_df[\"proximity\"].value_counts().reset_index()\n",
    "summary.columns = [\"Proximity Range\", \"Number of Duplicate Pairs\"]\n",
    "print(\"📊 Summary of Duplicate LGD Village Proximities:\\n\")\n",
    "print(summary)\n",
    "\n",
    "# 🧾 Show top 10 farthest duplicates\n",
    "print(\"\\n🔎 Farthest duplicate LGD entries:\")\n",
    "print(distances_df.sort_values(by=\"distance_m\", ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e569911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\utkar\\AppData\\Local\\Temp\\ipykernel_6036\\987728937.py:30: UserWarning: Geometry column does not contain geometry.\n",
      "  villages_deduped_csv[\"geometry\"] = villages_deduped_csv[\"geometry\"].apply(lambda g: g.wkt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final deduplicated village file saved:\n",
      "📁 GeoJSON: C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final_deduplicated.geojson\n",
      "📁 CSV:     C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final_deduplicated.csv\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 📍 Load the original master village file\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final.geojson\"\n",
    "villages = gpd.read_file(village_path)\n",
    "\n",
    "# ✅ Clean and standardize LGD codes\n",
    "villages = villages.dropna(subset=[\"lgd_villagecode\"]).copy()\n",
    "villages[\"lgd_villagecode\"] = villages[\"lgd_villagecode\"].astype(str).str.strip()\n",
    "villages[\"lgd_districtcode\"] = villages[\"lgd_districtcode\"].astype(str).str.strip()\n",
    "\n",
    "# ✅ Drop all duplicates based on LGD village code\n",
    "villages_deduped = villages.drop_duplicates(subset=\"lgd_villagecode\", keep=\"first\").copy()\n",
    "\n",
    "# ✅ Recreate consistent village_id\n",
    "villages_deduped[\"village_id\"] = villages_deduped[\"lgd_districtcode\"] + \"_\" + villages_deduped[\"lgd_villagecode\"]\n",
    "\n",
    "# ✅ Save deduplicated version\n",
    "output_folder = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\"\n",
    "geojson_path = os.path.join(output_folder, \"master_villages_final_deduplicated.geojson\")\n",
    "csv_path = geojson_path.replace(\".geojson\", \".csv\")\n",
    "\n",
    "# Save GeoJSON\n",
    "villages_deduped.to_file(geojson_path, driver=\"GeoJSON\")\n",
    "\n",
    "# Save CSV (WKT geometry)\n",
    "villages_deduped_csv = villages_deduped.copy()\n",
    "villages_deduped_csv[\"geometry\"] = villages_deduped_csv[\"geometry\"].apply(lambda g: g.wkt)\n",
    "villages_deduped_csv.to_csv(csv_path, index=False)\n",
    "\n",
    "print(\"✅ Final deduplicated village file saved:\")\n",
    "print(f\"📁 GeoJSON: {geojson_path}\")\n",
    "print(f\"📁 CSV:     {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25fc4d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📦 Number of villages in deduplicated file: 51464\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# 📍 Path to final deduplicated GeoJSON file\n",
    "geojson_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final_deduplicated.geojson\"\n",
    "\n",
    "# ✅ Load the file\n",
    "villages_deduped = gpd.read_file(geojson_path)\n",
    "\n",
    "# 📊 Show number of rows\n",
    "print(f\"📦 Number of villages in deduplicated file: {len(villages_deduped)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd068e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Unique LGD village codes: 51464\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "# 📍 Path to deduplicated file\n",
    "geojson_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final_deduplicated.geojson\"\n",
    "\n",
    "# ✅ Load file\n",
    "villages = gpd.read_file(geojson_path)\n",
    "\n",
    "# 🔍 Count unique LGD codes\n",
    "unique_lgd_count = villages[\"lgd_villagecode\"].nunique()\n",
    "\n",
    "print(f\"🔎 Unique LGD village codes: {unique_lgd_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25658840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ OSRM engine is running and reachable.\n",
      "📍 Example snapped point: [85.729407, 20.457807]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# OSRM endpoint to check\n",
    "osrm_health_url = \"http://localhost:5000\"\n",
    "\n",
    "# Option 1: Use /nearest test on a known Odisha location (Bhubaneswar)\n",
    "test_coords = \"85.8312,20.2961\"\n",
    "nearest_url = f\"{osrm_health_url}/nearest/v1/driving/{test_coords}?number=1\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(nearest_url, timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        print(\"✅ OSRM engine is running and reachable.\")\n",
    "        data = response.json()\n",
    "        snapped_point = data[\"waypoints\"][0][\"location\"]\n",
    "        print(f\"📍 Example snapped point: {snapped_point}\")\n",
    "    else:\n",
    "        print(f\"⚠️ OSRM responded with status code: {response.status_code}\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(\"❌ OSRM engine is not reachable.\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb7b38f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Starting snapping of villages via OSRM...\n",
      "   ➤ 0 villages processed...\n",
      "   ➤ 1000 villages processed...\n",
      "   ➤ 2000 villages processed...\n",
      "   ➤ 3000 villages processed...\n",
      "   ➤ 4000 villages processed...\n",
      "   ➤ 5000 villages processed...\n",
      "   ➤ 6000 villages processed...\n",
      "   ➤ 7000 villages processed...\n",
      "   ➤ 8000 villages processed...\n",
      "   ➤ 9000 villages processed...\n",
      "   ➤ 10000 villages processed...\n",
      "   ➤ 11000 villages processed...\n",
      "   ➤ 12000 villages processed...\n",
      "   ➤ 13000 villages processed...\n",
      "   ➤ 14000 villages processed...\n",
      "   ➤ 15000 villages processed...\n",
      "   ➤ 16000 villages processed...\n",
      "   ➤ 17000 villages processed...\n",
      "   ➤ 18000 villages processed...\n",
      "   ➤ 19000 villages processed...\n",
      "   ➤ 20000 villages processed...\n",
      "   ➤ 21000 villages processed...\n",
      "   ➤ 22000 villages processed...\n",
      "   ➤ 23000 villages processed...\n",
      "   ➤ 24000 villages processed...\n",
      "   ➤ 25000 villages processed...\n",
      "   ➤ 26000 villages processed...\n",
      "   ➤ 27000 villages processed...\n",
      "   ➤ 28000 villages processed...\n",
      "   ➤ 29000 villages processed...\n",
      "   ➤ 30000 villages processed...\n",
      "   ➤ 31000 villages processed...\n",
      "   ➤ 32000 villages processed...\n",
      "   ➤ 33000 villages processed...\n",
      "   ➤ 34000 villages processed...\n",
      "   ➤ 35000 villages processed...\n",
      "   ➤ 36000 villages processed...\n",
      "   ➤ 37000 villages processed...\n",
      "   ➤ 38000 villages processed...\n",
      "   ➤ 39000 villages processed...\n",
      "   ➤ 40000 villages processed...\n",
      "   ➤ 41000 villages processed...\n",
      "   ➤ 42000 villages processed...\n",
      "   ➤ 43000 villages processed...\n",
      "   ➤ 44000 villages processed...\n",
      "   ➤ 45000 villages processed...\n",
      "   ➤ 46000 villages processed...\n",
      "   ➤ 47000 villages processed...\n",
      "   ➤ 48000 villages processed...\n",
      "   ➤ 49000 villages processed...\n",
      "   ➤ 50000 villages processed...\n",
      "   ➤ 51000 villages processed...\n",
      "\n",
      "✅ Snapping complete. Saved to:\n",
      "📁 C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\Snapped_villages\\snapped_villages_osrm.geojson\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import requests\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import os\n",
    "\n",
    "# 📍 Input path: clean, deduplicated villages\n",
    "village_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\master_villages_final_deduplicated.geojson\"\n",
    "\n",
    "# 📂 Output path (create Snapped_villages folder if needed)\n",
    "output_folder = os.path.join(os.path.dirname(village_path), \"Snapped_villages\")\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, \"snapped_villages_osrm.geojson\")\n",
    "\n",
    "# ✅ Load and ensure WGS84\n",
    "villages = gpd.read_file(village_path).to_crs(epsg=4326)\n",
    "\n",
    "# 🔁 Snap each point using OSRM /nearest\n",
    "snapped_geoms = []\n",
    "osrm_url = \"http://localhost:5000/nearest/v1/driving\"\n",
    "\n",
    "print(\"🚀 Starting snapping of villages via OSRM...\")\n",
    "for idx, row in villages.iterrows():\n",
    "    lon, lat = row.geometry.x, row.geometry.y\n",
    "    query = f\"{osrm_url}/{lon},{lat}?number=1\"\n",
    "    \n",
    "    try:\n",
    "        res = requests.get(query)\n",
    "        res.raise_for_status()\n",
    "        snapped = res.json()[\"waypoints\"][0][\"location\"]\n",
    "        snapped_geoms.append(Point(snapped[0], snapped[1]))\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Index {idx}: {e}\")\n",
    "        snapped_geoms.append(Point(lon, lat))  # fallback to original\n",
    "\n",
    "    if idx % 1000 == 0:\n",
    "        print(f\"   ➤ {idx} villages processed...\")\n",
    "    time.sleep(0.001)\n",
    "\n",
    "# ✅ Replace geometry and save\n",
    "villages[\"geometry\"] = snapped_geoms\n",
    "villages.to_file(output_path, driver=\"GeoJSON\")\n",
    "\n",
    "print(f\"\\n✅ Snapping complete. Saved to:\\n📁 {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "065cae39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧾 Columns in master dataset:\n",
      "['Statename', 'Districtname', 'Subdistrictname', 'Blockname', 'Healthblockname', 'Healthfacilitytype', 'Facilityname', 'NIN', 'latitude', 'longitude', 'facility_type_standardized']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_csv = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\snapping_inputs\\master_dataset_final.csv\"\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "print(\"🧾 Columns in master dataset:\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d518bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Snapping input files saved in:\n",
      "C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\snapping_inputs\\facilities_by_type\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# ✅ Corrected path to your final cleaned facility master file\n",
    "final_path = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\snapping_inputs\\master_dataset_final.csv\"\n",
    "\n",
    "# ✅ Load the dataset\n",
    "df = pd.read_csv(final_path)\n",
    "\n",
    "# ✅ Create output folder (if not already exists)\n",
    "snapping_dir = os.path.join(os.path.dirname(final_path), \"facilities_by_type\")\n",
    "os.makedirs(snapping_dir, exist_ok=True)\n",
    "\n",
    "# ✅ Standardize column names for consistent grouping\n",
    "df['Districtname'] = df['Districtname'].astype(str).str.strip().str.lower()\n",
    "df['facility_type_standardized'] = df['facility_type_standardized'].astype(str).str.strip().str.lower()\n",
    "\n",
    "# ✅ Group and save by facility type and district\n",
    "grouped = df.groupby(['facility_type_standardized', 'Districtname'])\n",
    "\n",
    "for (ftype, district), group_df in grouped:\n",
    "    fname = f\"{district}_{ftype}.csv\".replace(\" \", \"_\")\n",
    "    fpath = os.path.join(snapping_dir, fname)\n",
    "    group_df.to_csv(fpath, index=False)\n",
    "\n",
    "print(f\"✅ Snapping input files saved in:\\n{snapping_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc9273d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Snapping 139 facility files...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:46<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Summary of Snapping:\n",
      "✅ anugul_chc.csv snapped and saved.\n",
      "✅ anugul_dh.csv snapped and saved.\n",
      "✅ anugul_hsc.csv snapped and saved.\n",
      "✅ anugul_phc.csv snapped and saved.\n",
      "✅ anugul_sdh.csv snapped and saved.\n",
      "✅ balangir_chc.csv snapped and saved.\n",
      "✅ balangir_dh.csv snapped and saved.\n",
      "✅ balangir_hsc.csv snapped and saved.\n",
      "✅ balangir_phc.csv snapped and saved.\n",
      "✅ balangir_sdh.csv snapped and saved.\n",
      "✅ baleshwar_chc.csv snapped and saved.\n",
      "✅ baleshwar_dh.csv snapped and saved.\n",
      "✅ baleshwar_hsc.csv snapped and saved.\n",
      "✅ baleshwar_phc.csv snapped and saved.\n",
      "✅ baleshwar_sdh.csv snapped and saved.\n",
      "✅ bargarh_chc.csv snapped and saved.\n",
      "✅ bargarh_dh.csv snapped and saved.\n",
      "✅ bargarh_hsc.csv snapped and saved.\n",
      "✅ bargarh_phc.csv snapped and saved.\n",
      "✅ bargarh_sdh.csv snapped and saved.\n",
      "✅ bhadrak_chc.csv snapped and saved.\n",
      "✅ bhadrak_dh.csv snapped and saved.\n",
      "✅ bhadrak_hsc.csv snapped and saved.\n",
      "✅ bhadrak_phc.csv snapped and saved.\n",
      "✅ boudh_chc.csv snapped and saved.\n",
      "✅ boudh_dh.csv snapped and saved.\n",
      "✅ boudh_hsc.csv snapped and saved.\n",
      "✅ boudh_phc.csv snapped and saved.\n",
      "✅ cuttack_chc.csv snapped and saved.\n",
      "✅ cuttack_dh.csv snapped and saved.\n",
      "✅ cuttack_hsc.csv snapped and saved.\n",
      "✅ cuttack_phc.csv snapped and saved.\n",
      "✅ cuttack_sdh.csv snapped and saved.\n",
      "✅ deogarh_chc.csv snapped and saved.\n",
      "✅ deogarh_dh.csv snapped and saved.\n",
      "✅ deogarh_hsc.csv snapped and saved.\n",
      "✅ deogarh_phc.csv snapped and saved.\n",
      "✅ dhenkanal_chc.csv snapped and saved.\n",
      "✅ dhenkanal_dh.csv snapped and saved.\n",
      "✅ dhenkanal_hsc.csv snapped and saved.\n",
      "✅ dhenkanal_phc.csv snapped and saved.\n",
      "✅ dhenkanal_sdh.csv snapped and saved.\n",
      "✅ gajapati_chc.csv snapped and saved.\n",
      "✅ gajapati_dh.csv snapped and saved.\n",
      "✅ gajapati_hsc.csv snapped and saved.\n",
      "✅ gajapati_phc.csv snapped and saved.\n",
      "✅ ganjam_chc.csv snapped and saved.\n",
      "✅ ganjam_dh.csv snapped and saved.\n",
      "✅ ganjam_hsc.csv snapped and saved.\n",
      "✅ ganjam_phc.csv snapped and saved.\n",
      "✅ ganjam_sdh.csv snapped and saved.\n",
      "✅ jagatsinghapur_chc.csv snapped and saved.\n",
      "✅ jagatsinghapur_dh.csv snapped and saved.\n",
      "✅ jagatsinghapur_hsc.csv snapped and saved.\n",
      "✅ jagatsinghapur_phc.csv snapped and saved.\n",
      "✅ jajapur_chc.csv snapped and saved.\n",
      "✅ jajapur_dh.csv snapped and saved.\n",
      "✅ jajapur_hsc.csv snapped and saved.\n",
      "✅ jajapur_phc.csv snapped and saved.\n",
      "✅ jharsuguda_chc.csv snapped and saved.\n",
      "✅ jharsuguda_dh.csv snapped and saved.\n",
      "✅ jharsuguda_hsc.csv snapped and saved.\n",
      "✅ jharsuguda_phc.csv snapped and saved.\n",
      "✅ kalahandi_chc.csv snapped and saved.\n",
      "✅ kalahandi_dh.csv snapped and saved.\n",
      "✅ kalahandi_hsc.csv snapped and saved.\n",
      "✅ kalahandi_phc.csv snapped and saved.\n",
      "✅ kalahandi_sdh.csv snapped and saved.\n",
      "✅ kandhamal_chc.csv snapped and saved.\n",
      "✅ kandhamal_dh.csv snapped and saved.\n",
      "✅ kandhamal_hsc.csv snapped and saved.\n",
      "✅ kandhamal_phc.csv snapped and saved.\n",
      "✅ kandhamal_sdh.csv snapped and saved.\n",
      "✅ kendrapara_chc.csv snapped and saved.\n",
      "✅ kendrapara_dh.csv snapped and saved.\n",
      "✅ kendrapara_hsc.csv snapped and saved.\n",
      "✅ kendrapara_phc.csv snapped and saved.\n",
      "✅ kendrapara_sdh.csv snapped and saved.\n",
      "✅ kendujhar_chc.csv snapped and saved.\n",
      "✅ kendujhar_dh.csv snapped and saved.\n",
      "✅ kendujhar_hsc.csv snapped and saved.\n",
      "✅ kendujhar_phc.csv snapped and saved.\n",
      "✅ kendujhar_sdh.csv snapped and saved.\n",
      "✅ khordha_chc.csv snapped and saved.\n",
      "✅ khordha_dh.csv snapped and saved.\n",
      "✅ khordha_hsc.csv snapped and saved.\n",
      "✅ khordha_phc.csv snapped and saved.\n",
      "✅ koraput_chc.csv snapped and saved.\n",
      "✅ koraput_dh.csv snapped and saved.\n",
      "✅ koraput_hsc.csv snapped and saved.\n",
      "✅ koraput_phc.csv snapped and saved.\n",
      "✅ malkangiri_chc.csv snapped and saved.\n",
      "✅ malkangiri_dh.csv snapped and saved.\n",
      "✅ malkangiri_hsc.csv snapped and saved.\n",
      "✅ malkangiri_phc.csv snapped and saved.\n",
      "✅ malkangiri_sdh.csv snapped and saved.\n",
      "✅ mayurbhanj_chc.csv snapped and saved.\n",
      "✅ mayurbhanj_dh.csv snapped and saved.\n",
      "✅ mayurbhanj_hsc.csv snapped and saved.\n",
      "✅ mayurbhanj_phc.csv snapped and saved.\n",
      "✅ mayurbhanj_sdh.csv snapped and saved.\n",
      "✅ nabarangpur_chc.csv snapped and saved.\n",
      "✅ nabarangpur_dh.csv snapped and saved.\n",
      "✅ nabarangpur_hsc.csv snapped and saved.\n",
      "✅ nabarangpur_phc.csv snapped and saved.\n",
      "✅ nabarangpur_sdh.csv snapped and saved.\n",
      "✅ nayagarh_chc.csv snapped and saved.\n",
      "✅ nayagarh_dh.csv snapped and saved.\n",
      "✅ nayagarh_hsc.csv snapped and saved.\n",
      "✅ nayagarh_phc.csv snapped and saved.\n",
      "✅ nuapada_chc.csv snapped and saved.\n",
      "✅ nuapada_dh.csv snapped and saved.\n",
      "✅ nuapada_hsc.csv snapped and saved.\n",
      "✅ nuapada_phc.csv snapped and saved.\n",
      "✅ nuapada_sdh.csv snapped and saved.\n",
      "✅ puri_chc.csv snapped and saved.\n",
      "✅ puri_dh.csv snapped and saved.\n",
      "✅ puri_hsc.csv snapped and saved.\n",
      "✅ puri_phc.csv snapped and saved.\n",
      "✅ rayagada_chc.csv snapped and saved.\n",
      "✅ rayagada_dh.csv snapped and saved.\n",
      "✅ rayagada_hsc.csv snapped and saved.\n",
      "✅ rayagada_phc.csv snapped and saved.\n",
      "✅ rayagada_sdh.csv snapped and saved.\n",
      "✅ sambalpur_chc.csv snapped and saved.\n",
      "✅ sambalpur_dh.csv snapped and saved.\n",
      "✅ sambalpur_hsc.csv snapped and saved.\n",
      "✅ sambalpur_phc.csv snapped and saved.\n",
      "✅ sambalpur_sdh.csv snapped and saved.\n",
      "✅ sonepur_chc.csv snapped and saved.\n",
      "✅ sonepur_dh.csv snapped and saved.\n",
      "✅ sonepur_hsc.csv snapped and saved.\n",
      "✅ sonepur_phc.csv snapped and saved.\n",
      "✅ sonepur_sdh.csv snapped and saved.\n",
      "✅ sundargarh_chc.csv snapped and saved.\n",
      "✅ sundargarh_dh.csv snapped and saved.\n",
      "✅ sundargarh_hsc.csv snapped and saved.\n",
      "✅ sundargarh_phc.csv snapped and saved.\n",
      "✅ sundargarh_sdh.csv snapped and saved.\n",
      "\n",
      "✅ All snapped files saved to:\n",
      "C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\snapping_inputs\\snapped_facilities_by_type\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# ✅ Input and output paths\n",
    "input_dir = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\snapping_inputs\\facilities_by_type\"\n",
    "output_dir = input_dir.replace(\"facilities_by_type\", \"snapped_facilities_by_type\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# ✅ OSRM endpoint\n",
    "OSRM_URL = \"http://localhost:5000/nearest/v1/driving/{lon},{lat}?number=1\"\n",
    "\n",
    "# ✅ Function to snap a single facility\n",
    "def snap_point(row):\n",
    "    try:\n",
    "        url = OSRM_URL.format(lon=row[\"longitude\"], lat=row[\"latitude\"])\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status()\n",
    "        snapped = response.json()\n",
    "        if snapped and snapped[\"waypoints\"]:\n",
    "            snapped_coords = snapped[\"waypoints\"][0][\"location\"]\n",
    "            return pd.Series({\"snapped_lon\": snapped_coords[0], \"snapped_lat\": snapped_coords[1]})\n",
    "    except Exception:\n",
    "        return pd.Series({\"snapped_lon\": None, \"snapped_lat\": None})\n",
    "\n",
    "# ✅ Function to process one file\n",
    "def process_file(file):\n",
    "    try:\n",
    "        input_path = os.path.join(input_dir, file)\n",
    "        df = pd.read_csv(input_path)\n",
    "        \n",
    "        if \"latitude\" in df.columns and \"longitude\" in df.columns:\n",
    "            snapped_points = df[[\"latitude\", \"longitude\"]].apply(snap_point, axis=1)\n",
    "            df = pd.concat([df, snapped_points], axis=1)\n",
    "\n",
    "            output_path = os.path.join(output_dir, file)\n",
    "            df.to_csv(output_path, index=False)\n",
    "            return f\"✅ {file} snapped and saved.\"\n",
    "        else:\n",
    "            return f\"⚠️ Skipped {file}: missing lat/lon columns.\"\n",
    "    except Exception as e:\n",
    "        return f\"❌ Error processing {file}: {e}\"\n",
    "\n",
    "# ✅ List CSVs and run in parallel\n",
    "csv_files = [f for f in os.listdir(input_dir) if f.endswith(\".csv\")]\n",
    "\n",
    "print(f\"🚀 Snapping {len(csv_files)} facility files...\\n\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    results = list(tqdm(executor.map(process_file, csv_files), total=len(csv_files)))\n",
    "\n",
    "# ✅ Summary\n",
    "print(\"\\n📋 Summary of Snapping:\")\n",
    "for r in results:\n",
    "    print(r)\n",
    "\n",
    "print(f\"\\n✅ All snapped files saved to:\\n{output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a423ac47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🛣 Distance: 75.46 km\n",
      "⏱ Duration: 60.58 minutes\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import requests\n",
    "# 📍 Example: Anugul CHC\n",
    "chc_fp = r\"C:\\Users\\utkar\\OneDrive\\Desktop\\ClimateXTelemedicine Odisha\\Odisha_VScode\\.venv\\Policy note\\Final Version\\snapping_inputs\\snapped_facilities_by_type\\anugul_chc.csv\"\n",
    "\n",
    "# ✅ Load and convert to GeoDataFrame\n",
    "df_chc = pd.read_csv(chc_fp)\n",
    "gdf_chc = gpd.GeoDataFrame(df_chc, geometry=gpd.points_from_xy(df_chc['snapped_lon'], df_chc['snapped_lat']), crs=\"EPSG:4326\")\n",
    "# 📍 Example coordinates for a village (replace with real one)\n",
    "start_lat, start_lon = 20.504, 85.678  # village coordinates\n",
    "\n",
    "# ✅ Destination: first CHC from the snapped file\n",
    "end_lat, end_lon = gdf_chc.iloc[0]['snapped_lat'], gdf_chc.iloc[0]['snapped_lon']\n",
    "\n",
    "# 🛣 Run OSRM route request\n",
    "url = f\"http://localhost:5000/route/v1/driving/{start_lon},{start_lat};{end_lon},{end_lat}?overview=full&geometries=geojson\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200 and \"routes\" in response.json():\n",
    "    route = response.json()[\"routes\"][0]\n",
    "    print(f\"🛣 Distance: {route['distance'] / 1000:.2f} km\")\n",
    "    print(f\"⏱ Duration: {route['duration'] / 60:.2f} minutes\")\n",
    "else:\n",
    "    print(\"❌ Routing failed:\", response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc280736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🗺️ Map saved to: sample_route_map.html\n"
     ]
    }
   ],
   "source": [
    "import folium\n",
    "\n",
    "# 📍 Center the map around the midpoint\n",
    "mid_lat = (start_lat + end_lat) / 2\n",
    "mid_lon = (start_lon + end_lon) / 2\n",
    "m = folium.Map(location=[mid_lat, mid_lon], zoom_start=9)\n",
    "\n",
    "# 🏡 Start: Village\n",
    "folium.Marker([start_lat, start_lon], tooltip=\"Village\", icon=folium.Icon(color='blue')).add_to(m)\n",
    "\n",
    "# 🏥 End: CHC\n",
    "folium.Marker([end_lat, end_lon], tooltip=\"Snapped CHC\", icon=folium.Icon(color='green')).add_to(m)\n",
    "\n",
    "# 🛣 Add route (if exists)\n",
    "coords = response.json()['routes'][0]['geometry']['coordinates']\n",
    "route_coords = [[lat, lon] for lon, lat in coords]  # flip lon-lat to lat-lon for Folium\n",
    "folium.PolyLine(route_coords, color='red', weight=5, opacity=0.8).add_to(m)\n",
    "\n",
    "# Show map\n",
    "m.save(\"sample_route_map.html\")\n",
    "print(\"🗺️ Map saved to: sample_route_map.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
